---
title: "What do Facebook or X users say about farming communities?"
subtitle: "Word cloud analysis using R"
author: 
  - name: "Shuyu Zhang"
    correspondence: "yes"
    email: "S.Zhang-19@tudelft.nl"
    affiliations: 
      - ref: tud
  - name: "Claudiu Forgaci"
    email: C.Forgaci@tudelft.nl
    orcid: 0000-0003-3218-5102
    affiliations: 
      - ref: tud
affiliations:
  - id: tud
    name: Delft University of Technology
    address: Julianalaan 134, 2628 BL, Delft, Zuid-Holland, The Netherlands
date: "20 March 2024"
format: html
toc: true
include-in-header:
  - text: |
      <style>
      .cell-output-stdout code {
        word-break: break-wor !important;
        white-space: pre-wrap !important;
      }
      </style>
---

::: callout-note
If you are reading the source document `script_socialmedia.qmd` and want to see a rendered version in your browser, click on the Render button above this window.
:::

## Setup

### Software for data collection

During the workshop, we work with [Web Data Research Assistant](https://southampton.ac.uk/~lac/WebDataResearchAssistant/) for scraping Facebook and X data. Web Data Research Assistant is a web browser extension allowing you to scrape data from the web, in particular from Twitter, Facebook, Google (does not work for Google Maps), and Instagram.

1.  Make sure you are using Google Chrome as your web browser. If you don't have it, download and install it from [here](https://www.google.com/chrome/).

2.  Install the Web Data Reseach Assistant extension from [here](https://chromewebstore.google.com/detail/web-data-research-assista/kcdbekkmigohaijilebpaeoopcgjbbdm?pli=1).

3.  In Chrome, go to Facebook or X and search for keywords you are interested in, then press <kbd>Shift</kbd>+<kbd>Ctrl</kbd>+<kbd>A</kbd> to activate the data gathering process. ![](fig/webscraping1.png)

4.  Press <kbd>Shift</kbd>+<kbd>Ctrl</kbd>+<kbd>H</kbd> to halt the data gathering process and stop the browser scrolling. You will be prompted to save a `WebDataRE.html` file. ![](fig/webscraping2.png)

5.  Open the `WebDataRE.html`, select the data in the table (including the column headers), open a new Excel file and paste the copied data into it. ![](fig/webscraping3.png)

### Software for analysing data

1.  During the workshop, we work in [a cloud instance of RStudio](http://rstudio-server-edu.bk.tudelft.nl:8787/) accessible through your web browser, so no installation is required. After the workshop, you will need to install [R, RStudio Desktop](https://posit.co/download/rstudio-desktop/) and [Python](https://www.python.org/downloads/) for your operating system.

2.  In RStudio, create a new project from `File > New Project... > Version Control > Git` with the URL `https://github.com/cforgaci/mint2324Q3U.git` and project directory name `mint2324Q3U`. Browse to a location of your choice on your computer and click on `Create Project`. This will create a project directory populated with the data scripts used in the workshop.

3.  Open `script_socialmedia.qmd`. This will bring you to the computational notebook from where this document was rendered. Activate the visual editor and continue reading there. ![](fig/rstudio.png)

4.  For our analysis, we will need to load a number of R packages that extend the out-of-the-box functionality of R. Run the `setup` code chunk below by pressing on the green arrow in its upper right corner.

-   If you are running this script in RStudio Desktop, you will need to first run the `install` code below, by deleting the two `#` signs and running the code chunk. It will take a few of minutes until all packages are installed.

```{r install, eval=FALSE}
# if (!"renv" %in% installed.packages()) install.packages("renv")
# renv::restore(prompt = FALSE)
```

-   Run this code to load the packages we will use in this document

```{r setup, message=FALSE}
library(tidyverse)        # Data manipulation and visualisation
library(tidytext)         # Text manipulation
library(wordcloud)        # Generate word clouds
require(reshape2)         # wordcloud dependency
library(readxl)           # Read Excel files in R
library(stopwords)        # Provides stopwords lists for multiple languages
library(tm)               # Create and manipulate corpora
```

## Introduction

In this workshop, we will use word clouds to reveal top keywords in the Facebook or X about farmer communities.

### The dataset

We will do this together on a given dataset: two data frames of Excel files which generated by Web Data Research Assistant and translated by Google. The one is from Facebook and another is from X. In this instruction, we will work with data frames of social media X. After that, you will run the analysis in this document on a dataset of your choice. Run the following code chunk with the default value.

```{r}
# What data will you work with? Use one of the following two values:
# - "facebook_x" if you want to use the default dataset
# - "mydata" if you want to use your own dataset
data_choice <- "facebook_x"
```

## Text analysis

Read the Excel files of facebook or X in R. We use an Excel file with X data as an example.

```{r readxl}
# read the excel data from folder, using data from x for example
data_root <- paste0("data/", data_choice, "/", "x#boeren_nederland_EN.xlsx")
fsq <- read_excel(data_root)
```

At this step, we define a list of stop words that occur in high frequency across the entire set of documents and are not expected to add meaning to the topics.

```{r stopwords}
stopwords_vec <- stopwords()
custom_stopwords_vec <- c("https", "twitter", "x", "also", "think", "must", "know", "many", "much", "like", "everything", "really", "want","without", "going", "good", "something", "farmers", "netherlands", "nthe" )
```

We choose the column of text information, split the entire corpus into words and filter them with some rules...

```{r tokens, warning=FALSE}
fsq_words <- fsq %>% 
  unnest_tokens(output = token, input = Text) %>%  # Decide which text information in which columns you want to analyze, and input = "name of column"
  filter(!token %in% stopwords_vec) %>%  # Remove English stop words
  filter(!token %in% custom_stopwords_vec) %>%  # Remove custom stop words
  filter(!str_detect(token, "[0-9]")) %>%  # Remove numbers
  filter(nchar(token) > 3)  # Remove words of max. 3 characters
```

... and have a quick look at the most frequently used words. We can see frequently used words such as "people", "food", and "policy" "right" indicating different areas of concern present in social media posts. Note that we have 1609 rows, each representing one distinct word. This is the vocabulary we will provide as input to the word cloud.

```{r tokens-rank}
# Count the token frequency
fsq_words %>% 
  count(token) %>% 
  arrange(desc(n))
```

We select top 100 words and make a word cloud

```{r wordcloud}
# Select top 100 words
fsq_words_top100 <- fsq_words %>% 
  count(token) %>%  
  slice_max(n, n = 100) 

# Generate a word cloud with the filtered data
wordcloud(words = fsq_words_top100$token, freq = fsq_words_top100$n, 
          colors = rainbow(length(fsq_words_top100$token)), scale=c(3, 0.2))
```

## Now it's your turn!

### Exercise: Visualising scraped data

You've been scraping data throughout the workshop. Now it is time to visualise it. 

1.  In the `Files` tab of RStudio, click on `Upload`. Navigate to the target directory `~/mint2324Q3U/data/facebook_x`, click on `Choose File` to select the Excel file with your scraped data and click on `OK`.

2.  On line 102 of this script, replace `x#boeren_nederland_EN.xlsx` with the name of your uploaded file.

3. Follow the steps of the web scraping tutorial above to visualise your social media data in a word cloud. 

What do you see? How would you describe the discourse of/about farming communities on social media?
